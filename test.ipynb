{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initiating Detector variables\n",
      "[INFO] loading model...\n",
      "[INFO] starting video stream...\n",
      "[INFO] Stream open:  True\n",
      "[INFO] starting process...\n",
      "[INFO] starting Classifier Process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-9859d71044ab>\", line 173, in classify_frame\n",
      "    self.outputQueue.put(self.detections)\n",
      "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "##############\n",
    "# TODO\n",
    "#############\n",
    "\n",
    "# Put paths/IPs into arguments\n",
    "# Add Bounding Boxes\n",
    "# Figure out additional Cameras\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from imutils.video import FPS\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Queue\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import threading\n",
    "import sys\n",
    "\n",
    "\n",
    "    \n",
    "args = {\n",
    "    'model': '/playground/Smart-Motion-Detector/MobileNetSSD_deploy.caffemodel',\n",
    "    'prototxt': '/playground/Smart-Motion-Detector/MobileNetSSD_deploy.prototxt.txt',\n",
    "    'confidence': 0.6\n",
    "}\n",
    "\n",
    "classes_detected = []\n",
    "labels_detected = []\n",
    "\n",
    "stop_recording_after = 80\n",
    "person_counter = 0\n",
    "no_person_counter = 0\n",
    "detections = None\n",
    "last_frame = np.array(0)\n",
    "\n",
    "\n",
    "\n",
    "class detector:\n",
    "    \n",
    "    # Initiate Values\n",
    "    def __init__(self):\n",
    "        print('[INFO] initiating Detector variables')\n",
    "        self.confidence = 0\n",
    "        self.push_time = 0\n",
    "        self.r = {'text':None}\n",
    "        self.inputQueue = Queue(maxsize=1)\n",
    "        self.outputQueue = Queue(maxsize=1)\n",
    "        self.detections = None\n",
    "        self.testing = False\n",
    "        self.recording = False\n",
    "        self.frame = []\n",
    "        self.raw_frame = []\n",
    "        self.person_counter = 0\n",
    "        self.no_person_counter = 0\n",
    "        self.fH = 0\n",
    "        self.fW = 0\n",
    "        self.img_path = ''\n",
    "        \n",
    "        \n",
    "        \n",
    "        # load API Keys\n",
    "        self.keys=json.loads(open('/playground/Smart-Motion-Detector/keys.json').read())\n",
    "        self.pushover = self.keys['pushover']\n",
    "        self.pushover['message'] = 'Person detected! (new)'\n",
    "        \n",
    "        self.shinobi = self.keys['shinobi']\n",
    "        self.shinobi['GROUP_KEY'] = 'kcMz5HUxX4'\n",
    "        self.shinobi['MONITOR_ID'] = '9zwr33ysRF'\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def set_test_mode(self):\n",
    "        if self.testing:\n",
    "            self.testing = False\n",
    "            print(\"[INFO] ending test mode.\")\n",
    "        else:\n",
    "            self.testing = True\n",
    "            print(\"[INFO] running in test mode.\")\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def init_model(self, prototxt, model_path):\n",
    "        # load our serialized model from disk\n",
    "        print(\"[INFO] loading model...\")\n",
    "        self.net = cv2.dnn.readNetFromCaffe(prototxt, model_path)\n",
    "        # initialize the list of class labels MobileNet SSD was trained to\n",
    "        self.CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "            \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "            \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "            \"sofa\", \"train\", \"tvmonitor\"]\n",
    "        # detect, then generate a set of bounding box colors for each class\n",
    "        self.COLORS = np.random.uniform(0, 255, size=(len(self.CLASSES), 3))\n",
    "\n",
    "    \n",
    "    def init_monitor(self,url):\n",
    "        print(\"[INFO] starting video stream...\")\n",
    "        self.vs = cv2.VideoCapture(url)\n",
    "        self.fps = FPS().start()\n",
    "        self.ret, self.raw_frame = self.vs.read()\n",
    "        print('[INFO] Stream open: ', self.vs.isOpened())\n",
    "        return self.vs\n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    def send_push(self): #', '.join(list(set(classes))) + ' detected!'\n",
    "        \"\"\"\n",
    "        print('[INFO] drawing boxes')\n",
    "        # compute the (x, y)-coordinates\n",
    "        # of the bounding box for the object\n",
    "        dims = np.array([self.fW, self.fH, self.fW, self.fH])\n",
    "        box = detections[0, 0, i, 3:7] * dims\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        # draw the prediction on the frame\n",
    "        cv2.rectangle(detector.frame, (startX, startY), (endX, endY),\n",
    "        detector.COLORS[idx], 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv2.putText(detector.frame, label, (startX, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, detector.COLORS[idx], 2)\n",
    "        \"\"\"\n",
    "        print('[INFO] storing boxed image to file')\n",
    "        self.img_path = '/playground/nvr/snapshots/' + time.strftime(\"%Y%m%d_%H%M%S\") + '.jpg'\n",
    "        cv2.imwrite(self.img_path, self.raw_frame)\n",
    "        \n",
    "        print('[INFO] sending Push Notification')\n",
    "        r = requests.post(\"https://api.pushover.net/1/messages.json\", data = self.pushover,\n",
    "        files = {\n",
    "          \"attachment\": (os.path.basename(self.img_path), open(self.img_path, \"rb\"), \"image/jpeg\")\n",
    "            })\n",
    "        print(r.text)\n",
    "\n",
    "        \n",
    "    def classify_frame(self):\n",
    "        print('[INFO] starting Classifier Process')\n",
    "        # keep looping\n",
    "        while True:\n",
    "            \"\"\"\n",
    "            if self.testing:\n",
    "                \n",
    "                \n",
    "            \"\"\"    \n",
    "            # check to see if there is a frame in our input queue\n",
    "            if not self.inputQueue.empty():\n",
    "                # grab the frame from the input queue, resize it, and\n",
    "                # construct a blob from it\n",
    "                self.frame = self.inputQueue.get()\n",
    "                self.raw_frame = self.frame\n",
    "                self.frame = cv2.resize(self.frame, (300, 300))\n",
    "                (self.fH, self.fW) = self.frame.shape[:2]\n",
    "                self.blob = cv2.dnn.blobFromImage(self.frame, 0.007843, (300, 300), 127.5)\n",
    "\n",
    "                # set the blob as input to our deep learning object\n",
    "                # detector and obtain the detections\n",
    "                self.net.setInput(self.blob)\n",
    "                self.detections = self.net.forward()\n",
    "\n",
    "                # write the detections to the output queue\n",
    "                self.outputQueue.put(self.detections)\n",
    "\n",
    "    def start_recording(self):\n",
    "        print('[INFO] starting recording')\n",
    "        r = requests.get('http://192.168.1.233:8080/' + self.shinobi['key']+ '/monitor/' + self.shinobi['GROUP_KEY'] + '/' + self.shinobi['MONITOR_ID'] + '/record')\n",
    "        self.recording = True\n",
    "        print(r.text)\n",
    "        return r \n",
    "\n",
    "    def stop_recording(self):\n",
    "        print('[INFO] stopping recording')\n",
    "        r = requests.get('http://192.168.1.233:8080/' + self.shinobi['key']+ '/monitor/' + self.shinobi['GROUP_KEY'] + '/' + self.shinobi['MONITOR_ID'] + '/start')\n",
    "        self.recording = False\n",
    "        print(r.text)\n",
    "        return r \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#create detector Object:\n",
    "detector = detector()\n",
    "\n",
    "\n",
    "\n",
    "#initiate detector Model:\n",
    "detector.init_model(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "vs = detector.init_monitor('rtsp://192.168.1.240:554/s1')\n",
    "\n",
    "\n",
    "# start background processes\n",
    "print(\"[INFO] starting process...\")\n",
    "classifier_process = Process(target=detector.classify_frame)\n",
    "classifier_process.daemon = True\n",
    "classifier_process.start()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting detector\n",
      "[INFO] no person detected since  80  frames\n",
      "[INFO] exiting program\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('[INFO] starting detector')\n",
    "\n",
    "\n",
    "while True: #for i in range(100):\n",
    "    try:\n",
    "        now = datetime.datetime.now()\n",
    "\n",
    "        # grab the frame from the threaded video stream, resize it, and\n",
    "        # grab its dimensions\n",
    "        ret, detector.raw_frame = vs.read()\n",
    "\n",
    "        if ret:\n",
    "            if np.array_equal(detector.raw_frame, last_frame):\n",
    "                print('[INFO] Frame not new')\n",
    "                continue\n",
    "\n",
    "            no_frame_counter = 0\n",
    "            if detector.testing:\n",
    "                detector.frame = cv2.imread('/playground/Smart-Motion-Detector/Pedestrian-Safety.jpg')\n",
    "            else:\n",
    "                detector.frame = detector.raw_frame\n",
    "            \n",
    "            \n",
    "\n",
    "            # if the input queue *is* empty, give the current frame to\n",
    "            # classify\n",
    "            if detector.inputQueue.empty():\n",
    "                detector.inputQueue.put(detector.frame)\n",
    "\n",
    "            if not detector.outputQueue.empty():\n",
    "                detections = detector.outputQueue.get()\n",
    "                \n",
    "            # check to see if our detectios are not None (and if so, we'll\n",
    "            # draw the detections on the frame)\n",
    "            if detections is not None:\n",
    "                #print('[INFO] Checking detections')\n",
    "                # reset detection lists:\n",
    "                classes_detected = []\n",
    "                labels_detected = []\n",
    "\n",
    "                # loop over detections\n",
    "                for i in np.arange(0, detections.shape[2]):\n",
    "                    # extract the confidence (i.e., probability) associated\n",
    "                    # with the prediction\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "                    # filter out weak detections by ensuring the `confidence`\n",
    "                    # is greater than the minimum confidence\n",
    "                    if confidence < args['confidence']:\n",
    "                        continue\n",
    "\n",
    "                    # extract the index of the class label from the `detections`\n",
    "                    idx = int(detections[0, 0, i, 1])\n",
    "\n",
    "                    label = \"{}: {:.2f}%\".format(detector.CLASSES[idx], confidence * 100)\n",
    "                    #print(label)\n",
    "\n",
    "                    labels_detected.append(label)\n",
    "                    classes_detected.append(detector.CLASSES[idx])\n",
    "\n",
    "                if 'person' not in classes_detected:\n",
    "                    \n",
    "                    #print('[INFO] No Person in Frame.')\n",
    "                    detector.no_person_counter = detector.no_person_counter + 1\n",
    "                    detector.person_counter = 0\n",
    "                    \n",
    "                    # if x frames without person, stop recording\n",
    "                    if detector.no_person_counter == stop_recording_after:\n",
    "                        print('[INFO] no person detected since ', detector.no_person_counter,' frames')\n",
    "                        if detector.recording:\n",
    "                            stop_recording_thread = threading.Thread(target=detector.stop_recording, args=())\n",
    "                            stop_recording_thread.daemon = True  # Daemonize thread\n",
    "                            stop_recording_thread.start() \n",
    "                    continue\n",
    "\n",
    "                print('[INFO] Person detected')\n",
    "\n",
    "                # set counters:\n",
    "                detector.no_person_counter = 0\n",
    "                detector.person_counter = detector.person_counter + 1\n",
    "\n",
    "                # send Push if person_couner == 0 (New detection in this session)\n",
    "                if detector.person_counter == 1 and not detector.recording:\n",
    "\n",
    "                    # take snapshot and send push\n",
    "                    send_push_thread = threading.Thread(target=detector.send_push, args=())\n",
    "                    send_push_thread.daemon = True  # Daemonize thread\n",
    "                    send_push_thread.start() \n",
    "\n",
    "                    # if camera is not recording, start recording:\n",
    "                    print('[INFO] shinobi is recording:', detector.recording)\n",
    "                    if not detector.recording:\n",
    "                        start_recording_thread = threading.Thread(target=detector.start_recording, args=())\n",
    "                        start_recording_thread.daemon = True # Daemonize thread\n",
    "                        start_recording_thread.start() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # If Video Stream returns no frame:\n",
    "        else:\n",
    "            no_frame_counter = no_frame_counter + 1\n",
    "            print('[INFO] no_frame_counter: ', no_frame_counter)\n",
    "            print('[INFO] Stream open?', vs.isOpened())\n",
    "\n",
    "            if no_frame_counter >= 10 or vs.isOpened() == False:\n",
    "                print('[INFO] Re-connecting Stream...')\n",
    "                vs = cv2.VideoCapture('rtsp://192.168.1.240:554/s1')\n",
    "                fps = FPS().start()\n",
    "                ret, detector.raw_frame = vs.read()\n",
    "                if ret:\n",
    "                    no_frame_counter = 0\n",
    "                continue\n",
    "\n",
    "        last_frame = detector.raw_frame\n",
    "    except KeyboardInterrupt:\n",
    "        print('[INFO] exiting program')\n",
    "        if detector.recording:\n",
    "            detector.stop_recording()\n",
    "            \n",
    "        sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
