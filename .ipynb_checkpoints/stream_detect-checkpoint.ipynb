{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Import Libraries\n",
    "################################################\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import datetime\n",
    "import shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Load Stuff\n",
    "################################################\n",
    "\n",
    "\n",
    "args =  {'classes': '/home/cichons/Smart-Motion-Detector/classes.txt',\n",
    "         'weights': '/home/cichons/Smart-Motion-Detector/yolov3.weights',\n",
    "         'config': '/home/cichons/Smart-Motion-Detector/yolov3.cfg',\n",
    "         'stream': 'rtsp://192.168.1.233:7447/5b75de05e4b0a018229f268f_2',\n",
    "         'cameraname': 'Auffahrt'\n",
    "        }\n",
    "\n",
    "\n",
    "# Load Pushover Key File\n",
    "data=json.loads(open('/home/cichons/Smart-Motion-Detector/keys.json').read())\n",
    "\n",
    "\n",
    "classes = None\n",
    "with open(args['classes'], 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Settings\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "LOG_FILE = '/home/cichons/unifi-video/logs/recording.log'\n",
    "WATCH_FOR = 'STOPPING REC'\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.6\n",
    "nms_threshold = 0.4\n",
    "scale = 0.00392\n",
    "time_between_push_notifications = 0 \n",
    "px_dist = 70 # Minumum Distance in Pixels between current and prevouis Detection\n",
    "\n",
    "\n",
    "\n",
    "target_classes = ['person',\n",
    " 'bicycle',\n",
    " 'car',\n",
    " 'motorcycle',\n",
    " 'bus',\n",
    " 'truck'\n",
    "]\n",
    "\n",
    "\n",
    "# Pushover Settings:\n",
    "data['priority'] = 1 #2\n",
    "data['retry'] = 30 \n",
    "data['expire'] = 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Set initial Values\n",
    "################################################\n",
    "\n",
    "\n",
    "mtime_last = 0\n",
    "dtime_last = 0\n",
    "\n",
    "net = cv2.dnn.readNet(args['weights'], args['config'])\n",
    "mtime_cur = datetime.datetime.now()\n",
    "recording_id = 'None'\n",
    "recording_id_last = ''\n",
    "centers_last = [-10, -10]\n",
    "boxes_last = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(args['stream'])\n",
    "\n",
    "\n",
    "_, frame = cap.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################\n",
    "# Defining Functions\n",
    "################################################\n",
    "\n",
    "# basic Python implementation of Unix tail for getting Tail of Log File\n",
    "def tail(file, n):\n",
    "    with open(file, \"r\") as f:\n",
    "        f.seek (0, 2)           # Seek @ EOF\n",
    "        fsize = f.tell()        # Get Size\n",
    "        f.seek (max (fsize-1024, 0), 0) # Set pos @ last n chars\n",
    "        lines = f.readlines()       # Read to end\n",
    "    lines = lines[-n:]    # Get last n lines\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id]) + ': ' + str(round(confidence*100, 2))\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Watching of ' + LOG_FILE + ' for ' + '*' + WATCH_FOR + '*' +\n",
    "    ' started at ' + time.strftime('%Y-%m-%d %I:%M:%S %p'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Watch Logfile for new Motion Recording\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while True:\n",
    "    try:\n",
    "        now = datetime.datetime.now()\n",
    "        date_path = str(now.year) + '/' + str(now.month if len(str(now.month)) == 2 else '0' + str(now.month)) + '/' + str(now.day if len(str(now.day)) == 2 else '0' + str(now.day))\n",
    "        # Monitor Log File:\n",
    "        for i in tail(LOG_FILE, 1):\n",
    "            if WATCH_FOR.lower() in i.lower():\n",
    "                mtime_cur = datetime.datetime.fromtimestamp(float(i.split(' ')[0]))\n",
    "                camera_name_id = i.split(\"[\")[1].split(\"]\")[0].split(\"|\")\n",
    "                start = i.split(\"START:\")[1].split(\" \")[0]\n",
    "                ts = datetime.datetime.fromtimestamp(int(start) / 1e3)\n",
    "                recording_id = i.split(\"motionRecording:\")[1].split(\" \")[0]\n",
    "                #recording_id = '5ba25ea1e4b0a01868310e29'\n",
    "                if recording_id == recording_id_last:\n",
    "                    continue\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------------------------------------------------------------')    \n",
    "                print(str(ts) + '   Found Motion Recording on Camera ' + ' '.join(camera_name_id) + '. Recording ID is: ' + recording_id)\n",
    "\n",
    "\n",
    "\n",
    "                confidences = []\n",
    "\n",
    "                for root, directories, filenames in os.walk('/home/cichons/unifi-video/videos/'+ cameras[camera_name_id[1]] + '/' + date_path):\n",
    "                    for filename in filenames: \n",
    "                        if fnmatch.fnmatch(filename, '*' + start + '*.mp4'):\n",
    "                            video_path = root +'/' + filename\n",
    "                        if fnmatch.fnmatch(filename, '*' + recording_id + '*full.jpg'):\n",
    "                            img_path = root +'/' + filename\n",
    "                            print(str(ts) + '   Running Object detection on: \\'' + img_path + '\\' from Camera: \\'' + ' '.join(camera_name_id) +'\\' ...')\n",
    "                            logger.info(str(ts) + '   Trigger Count: ' + str(i) + 'Motion detected on Camera: \\'' + ' '.join(camera_name_id) +'\\'   Running Object detection on: \\'' + img_path + '\\'')\n",
    "\n",
    "                            # Detect Objects:\n",
    "                            image = cv2.imread(img_path)\n",
    "                            if image is not None:\n",
    "                                try:\n",
    "                                    (Height, Width) = image.shape[:2]\n",
    "                                    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "                                    net.setInput(blob)\n",
    "                                    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "                                    boxes = []\n",
    "                                    class_ids = []\n",
    "                                    dtime_cur = time.time()\n",
    "                                    confidences = []\n",
    "                                    centers = []\n",
    "                                    for out in outs:\n",
    "                                        for detection in out:\n",
    "                                            scores = detection[5:]\n",
    "                                            class_id = np.argmax(scores)\n",
    "                                            confidence = scores[class_id]\n",
    "                                            if confidence > conf_threshold and classes[class_id] in target_classes:\n",
    "                                                print('confidence and class good')\n",
    "                                                center_x = int(detection[0] * Width)\n",
    "                                                center_y = int(detection[1] * Height)\n",
    "                                                centers.append([center_x, center_y])\n",
    "                                                w = int(detection[2] * Width)\n",
    "                                                h = int(detection[3] * Height)\n",
    "                                                x = center_x - w / 2\n",
    "                                                y = center_y - h / 2\n",
    "                                                class_ids.append(class_id)\n",
    "                                                confidences.append(float(confidence))\n",
    "                                                boxes.append([x, y, w, h])\n",
    "                                    if boxes == []:\n",
    "                                        print(\"No Object Detected.\")\n",
    "                                        continue\n",
    "\n",
    "                                    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "                                    if boxes != boxes_last:\n",
    "                                        print(boxes)\n",
    "                                        print(boxes_last)\n",
    "                                        for i in indices:\n",
    "                                            i = i[0]\n",
    "                                            box = boxes[i]\n",
    "                                            x = box[0]\n",
    "                                            y = box[1]\n",
    "                                            w = box[2]\n",
    "                                            h = box[3]\n",
    "                                            draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "\n",
    "                                        boxed_img_path = '/home/cichons/unifi-video/object_detections/'+ str(start) +'_'+ str(camera_name_id[1]) +'_'+ str(recording_id) + '.jpg' \n",
    "                                        cv2.imwrite(boxed_img_path, image)\n",
    "\n",
    "\n",
    "                                        cv2.waitKey()\n",
    "                                        # Calculate relative Distances between centers of new and previous detections:                                        \n",
    "                                        distances = abs(np.array([np.array(centers) - np.array(obj) for obj in centers_last]))\n",
    "\n",
    "                                        \n",
    "                                        print('centers', centers)\n",
    "                                        print('centers_last', centers_last)\n",
    "                                        \n",
    "                                        if boxes != boxes_last and confidences and np.max(distances) > px_dist and (dtime_cur - dtime_last) > time_between_push_notifications:\n",
    "                                            print('boxes differ', boxes != boxes_last)\n",
    "                                            print('confidences good', confidences)\n",
    "                                            print('distances ok', np.max(distances) > px_dist, distances)\n",
    "                                            print('time between notifications?', (dtime_cur - dtime_last) > time_between_push_notifications)\n",
    "\n",
    "\n",
    "                                            # Write to Log File\n",
    "                                            logger.info(str(ts) + '   ' + ', '.join(list(set([classes[i] for i in class_ids]))) + 'Trigger Count: ' + str(i) + ' detected on Camera: \\'' + ' '.join(camera_name_id) +'\\'   Video path is: \\'' + video_path + '\\'')\n",
    "\n",
    "                                            print(', '.join(list(set([classes[i] for i in class_ids]))) + ' detected!')\n",
    "\n",
    "                                            # Sent Push Notification via Pushover:\n",
    "                                            data['message'] = ', '.join(list(set([classes[i] for i in class_ids]))) + ' detected!'\n",
    "\n",
    "                                            r = requests.post(\"https://api.pushover.net/1/messages.json\", data = data,\n",
    "                                            files = {\n",
    "                                              \"attachment\": (filename, open(boxed_img_path, \"rb\"), \"image/jpeg\")\n",
    "                                            })\n",
    "\n",
    "                                            print(r.text)\n",
    "                                            dtime_last = dtime_cur\n",
    "                                        else:\n",
    "                                            print(\"Detected: \" + ', '.join(list(set([classes[i] for i in class_ids]))) + \". Notification unwanted.\")\n",
    "                                            print('boxes differ', boxes != boxes_last)\n",
    "                                            print('confidences good', confidences)\n",
    "                                            print('distances to previous detections ok', np.max(distances) > px_dist, distances)\n",
    "                                            print('time between notifications?', (dtime_cur - dtime_last) > time_between_push_notifications)\n",
    "                                            continue\n",
    "\n",
    "                                    boxes_last = boxes\n",
    "                                    centers_last = centers\n",
    "                                    #centers = []\n",
    "\n",
    "                                except Exception as err:\n",
    "                                    print(err)\n",
    "                                    continue\n",
    "\n",
    "                            else:\n",
    "                                print('image: ' + img_path + ' not found')\n",
    "                                continue\n",
    "                recording_id_last = recording_id\n",
    "                recording_id = ''\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
